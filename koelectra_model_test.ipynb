{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, ElectraForSequenceClassification\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# 모델과 토크나이저 불러오기\n",
        "num_classes = 6  # 클래스 수에 맞게 설정\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", num_labels=num_classes)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
        "\n",
        "# 저장된 모델 불러오기\n",
        "model.load_state_dict(torch.load(\"modelfinal.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = [\"중립\", \"슬픔\", \"분노\", \"불안\", \"행복\", \"당황\"]\n",
        "def predict_with_prob(input_sentence):\n",
        "    # 입력 문장을 토큰화하고 모델 입력 형식으로 변환\n",
        "    inputs = tokenizer(input_sentence, return_tensors=\"pt\", max_length=75, padding=True, truncation=True)\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "    \n",
        "    # 모델을 사용하여 감정 예측\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    \n",
        "    # 예측된 감정\n",
        "    predicted_class_idx = torch.argmax(logits, dim=1).item()\n",
        "    predicted_emotion = class_names[predicted_class_idx]\n",
        "\n",
        "    # 소프트맥스 함수를 사용하여 확률 계산\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    \n",
        "    # 각 클래스(감정)별 확률을 리스트로 변환\n",
        "    class_probs = probs.squeeze().tolist()\n",
        "\n",
        "    # 결과 반환\n",
        "    return predicted_emotion, class_probs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력한 문장: 학교가기 싫은데 친구들은 만나러 가고 싶어\n",
            "예측된 감정: 불안\n",
            "각 클래스별 확률:\n",
            "중립: 0.06%\n",
            "슬픔: 2.86%\n",
            "분노: 2.36%\n",
            "불안: 92.09%\n",
            "행복: 0.83%\n",
            "당황: 1.80%\n",
            "\n",
            "\n",
            "입력한 문장: 과제가 너무 많아서 화가나\n",
            "예측된 감정: 분노\n",
            "각 클래스별 확률:\n",
            "중립: 0.18%\n",
            "슬픔: 0.89%\n",
            "분노: 97.82%\n",
            "불안: 0.40%\n",
            "행복: 0.04%\n",
            "당황: 0.66%\n",
            "\n",
            "\n",
            "입력한 문장: 미안해 앞으로 잘할게\n",
            "예측된 감정: 슬픔\n",
            "각 클래스별 확률:\n",
            "중립: 0.75%\n",
            "슬픔: 97.47%\n",
            "분노: 0.62%\n",
            "불안: 0.37%\n",
            "행복: 0.10%\n",
            "당황: 0.69%\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 질문 무한반복하기! 0 입력시 종료\n",
        "end = 1\n",
        "while end == 1:\n",
        "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
        "    if sentence == \"0\":\n",
        "        break\n",
        "    print(\"입력한 문장:\", sentence)\n",
        "    \n",
        "    # 감정 예측 및 각 클래스(감정)별 확률 출력\n",
        "    predicted_emotion, class_probs = predict_with_prob(sentence)\n",
        "    print(\"예측된 감정:\", predicted_emotion)\n",
        "    print(\"각 클래스별 확률:\")\n",
        "    for class_name, prob in zip(class_names, class_probs):\n",
        "        print(f\"{class_name}: {prob*100:.2f}%\")\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
